[
  {
    "objectID": "st_558_hw5.html",
    "href": "st_558_hw5.html",
    "title": "ST 558 HW5: Non-linear modeling",
    "section": "",
    "text": "We’ll look at some machine learning modeling concepts and then practice using some methods."
  },
  {
    "objectID": "st_558_hw5.html#introduction",
    "href": "st_558_hw5.html#introduction",
    "title": "ST 558 HW5: Non-linear modeling",
    "section": "",
    "text": "We’ll look at some machine learning modeling concepts and then practice using some methods."
  },
  {
    "objectID": "st_558_hw5.html#task-1-conceptual-questions",
    "href": "st_558_hw5.html#task-1-conceptual-questions",
    "title": "ST 558 HW5: Non-linear modeling",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nWhat is the purpose of using cross-validation when fitting a random forest model?\n\n\nWe use cross-validation (CV) primarily to prevent overfitting. In the context of fitting a random forest model, we use it to determine the best hyperparameters given the data.\n\n\nDescribe the bagged tree algorithm.\n\n\nThis algorithm uses the standard classification and regression tree. First, it splits the predictor space up to look for cut points that minimize some loss function of interest. It does this repeatedly until the minimization is not useful. Ultimately, predictions consisting of the average response value for a terminal node for a numeric outcome, or the majority vote for a categorical outcome are made. The extra part added is bootstrap resampling to create many resamples, fitting a tree for each resample and creating predictions for each observation, then averaging these for numeric outcomes or taking the most common prediction for categorical outcomes. This averaging improves prediction accuracy at the cost of interpretability.\n\n\nWhat is meant by a general linear model?\n\n\nThis is a linear model with a continuous response that allows both continuous and categorical predictors.\n\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\n\nInteraction terms allow us to capture the change in effect from a predictor on a response in the presence of another predictor. They allow models to capture a multiplicative effect instead of only the additive effect provided by standalone predictors, changing the slopes of the models for each value of another predictor.\n\n\nWhy do we split our data into a training and test set?\n\n\nTo prevent overfitting by confirming our model’s prediction ability can generalize to unseen data, the test set, instead of only relying on the training set, which can produce overly optimisic results."
  },
  {
    "objectID": "st_558_hw5.html#task-2-fitting-models.",
    "href": "st_558_hw5.html#task-2-fitting-models.",
    "title": "ST 558 HW5: Non-linear modeling",
    "section": "Task 2: Fitting models.",
    "text": "Task 2: Fitting models.\nWe now practice fitting some models using the caret package.\nWe’ll read in data, drop ST_Slope create a heart disease factor variable, do some quick EDA, then preprocess for kNN modeling.\n\nIngest data, data cleaning, EDA, preprocess\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(GGally)\n\nLoading required package: ggplot2\n\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nheart_disease &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/heart.csv\") |&gt; \n  mutate(across(where(is.character), factor)) |&gt;\n  mutate(HeartDisease = ifelse(HeartDisease == 1, \"yes\", \"no\") |&gt; factor(levels = c(\"yes\", \"no\"))) |&gt; # heart disease factor var\n  select(-ST_Slope) # drop ST_Slope\n\nRows: 918 Columns: 12\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope\ndbl (7): Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak, HeartDisease\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#### EDA\n\n# Look at heart disease rates to get an idea of the no-information rate a model must beat\ntable(heart_disease$HeartDisease) |&gt; prop.table() # guessing majority class means we're right 55% of the time\n\n\n      yes        no \n0.5533769 0.4466231 \n\n# check missingness\nheart_disease |&gt; is.na() |&gt; colSums() # no NAs\n\n           Age            Sex  ChestPainType      RestingBP    Cholesterol \n             0              0              0              0              0 \n     FastingBS     RestingECG          MaxHR ExerciseAngina        Oldpeak \n             0              0              0              0              0 \n  HeartDisease \n             0 \n\nsummary(heart_disease) # cholesterol and resting bp have values of 0\n\n      Age        Sex     ChestPainType   RestingBP      Cholesterol   \n Min.   :28.00   F:193   ASY:496       Min.   :  0.0   Min.   :  0.0  \n 1st Qu.:47.00   M:725   ATA:173       1st Qu.:120.0   1st Qu.:173.2  \n Median :54.00           NAP:203       Median :130.0   Median :223.0  \n Mean   :53.51           TA : 46       Mean   :132.4   Mean   :198.8  \n 3rd Qu.:60.00                         3rd Qu.:140.0   3rd Qu.:267.0  \n Max.   :77.00                         Max.   :200.0   Max.   :603.0  \n   FastingBS       RestingECG      MaxHR       ExerciseAngina    Oldpeak       \n Min.   :0.0000   LVH   :188   Min.   : 60.0   N:547          Min.   :-2.6000  \n 1st Qu.:0.0000   Normal:552   1st Qu.:120.0   Y:371          1st Qu.: 0.0000  \n Median :0.0000   ST    :178   Median :138.0                  Median : 0.6000  \n Mean   :0.2331                Mean   :136.8                  Mean   : 0.8874  \n 3rd Qu.:0.0000                3rd Qu.:156.0                  3rd Qu.: 1.5000  \n Max.   :1.0000                Max.   :202.0                  Max.   : 6.2000  \n HeartDisease\n yes:508     \n no :410     \n             \n             \n             \n             \n\n# checking summaries by heart disease level\nheart_disease |&gt;\n  select(HeartDisease, where(is.numeric)) |&gt;\n  ggpairs()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n# heart disease and categorical\nheart_disease |&gt;\n  select(HeartDisease, where(is.factor)) |&gt; \n  ggpairs()\n\n\n\n\n\n\n\n\nNow, we create dummy variables for kNN.\n\nlibrary(caret)\n\nLoading required package: lattice\n\nheart_disease_dummies &lt;- dummyVars(~ . - HeartDisease, data = heart_disease) |&gt; \n  predict(heart_disease) |&gt; \n  bind_cols(heart_disease |&gt; select(HeartDisease))\n\n\n\nSplitting Data\nWe now split our data.\n\nset.seed(1312)\ntrain_test_split &lt;- createDataPartition(heart_disease_dummies$HeartDisease, p = 0.8, list = FALSE)\n\nheart_train &lt;- heart_disease_dummies[train_test_split,]\nheart_test &lt;- heart_disease_dummies[-train_test_split,]\n\n\n\nkNN Fit\nWe now fit several kNN models and do some cross-validation using train() from the caret package. We subsequently check performance with confusionMatrix().\n\n# setting cv options\ntrain_ctrl &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)\n\n# training knn models\nset.seed(1312)\nknn_fit &lt;- train(HeartDisease ~., data = heart_train, method = \"knn\",\n trControl=train_ctrl,\n preProcess = c(\"center\", \"scale\"),\n tuneGrid = data.frame(k = 1:40))\n\n# test predictions\ntest_pred &lt;- predict(knn_fit, heart_test)\n\nconfusionMatrix(test_pred, heart_test$HeartDisease)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction yes no\n       yes  82 10\n       no   19 72\n                                          \n               Accuracy : 0.8415          \n                 95% CI : (0.7804, 0.8912)\n    No Information Rate : 0.5519          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6829          \n                                          \n Mcnemar's Test P-Value : 0.1374          \n                                          \n            Sensitivity : 0.8119          \n            Specificity : 0.8780          \n         Pos Pred Value : 0.8913          \n         Neg Pred Value : 0.7912          \n             Prevalence : 0.5519          \n         Detection Rate : 0.4481          \n   Detection Prevalence : 0.5027          \n      Balanced Accuracy : 0.8450          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\nThe kNN model with 9 neighbors performs best here, attaining 84% accuracy compared to a No Information Rate of 55%.\n\n\nLogistic Regression\nNext we’ll fit three logistic regression models. Typically, age and sex seem to be sensible predictors based on medical studies and our EDA above. We can then add cholesterol as we always heart about how bad high cholesterol is for our health. Lastly we can use all predictors.\nWe’ll do another train/test split though because we don’t need to manually create dummy variables and we’ll run into issues if we use the dummy variable method that keeps a column for every variable.\nOnce we train the three models, we’ll compare them to see which one we select for test set evaluation.\n\nset.seed(477)\ntrain_split_logreg &lt;- createDataPartition(heart_disease$HeartDisease, p = .8, list = FALSE)\n\nheart_train_logreg &lt;- heart_disease[train_split_logreg,]\nheart_test_logreg &lt;- heart_disease[-train_split_logreg,]\n\n# basic logreg fit\nlogreg_fit1 &lt;- train(HeartDisease ~ Age + Sex, \n                     data = heart_train_logreg,\n                     method = \"glm\",\n                     trControl = train_ctrl,\n                     family = \"binomial\")\n\n# adding cholesterol\nlogreg_fit2 &lt;- train(HeartDisease ~ Age + Sex + Cholesterol, \n                     data = heart_train_logreg,\n                     method = \"glm\",\n                     trControl = train_ctrl,\n                     family = \"binomial\")\n\n# all predictors\nlogreg_fit3 &lt;- train(HeartDisease ~ ., \n                     data = heart_train_logreg,\n                     method = \"glm\",\n                     trControl = train_ctrl,\n                     family = \"binomial\")\n\n# comparing models\nresults &lt;- resamples(list(age_sex = logreg_fit1, age_sex_chol = logreg_fit2, all_vars = logreg_fit3))\n\nbwplot(results)\n\n\n\n\n\n\n\n\nCV results point to the logistic regression model with all predictors doing best. So we’ll use that specification for model summary and our test set evaluation. Note: we set HeartDisease’s reference level to “yes” so the negative coefficients point toward predictors that are associated with a higher heart disease risk.\n\nsummary(logreg_fit3)\n\n\nCall:\nNULL\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -0.615393   1.378760  -0.446 0.655353    \nAge              -0.015367   0.013490  -1.139 0.254631    \nSexM             -1.006141   0.271087  -3.712 0.000206 ***\nChestPainTypeATA  2.264999   0.326904   6.929 4.25e-12 ***\nChestPainTypeNAP  1.617530   0.259356   6.237 4.47e-10 ***\nChestPainTypeTA   1.642547   0.433032   3.793 0.000149 ***\nRestingBP        -0.001799   0.005899  -0.305 0.760333    \nCholesterol       0.004420   0.001160   3.811 0.000138 ***\nFastingBS        -1.338852   0.286548  -4.672 2.98e-06 ***\nRestingECGNormal  0.140337   0.279883   0.501 0.616079    \nRestingECGST      0.524856   0.359976   1.458 0.144832    \nMaxHR             0.010425   0.004877   2.137 0.032564 *  \nExerciseAnginaY  -1.271110   0.250682  -5.071 3.97e-07 ***\nOldpeak          -0.585924   0.118252  -4.955 7.24e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1010.42  on 734  degrees of freedom\nResidual deviance:  563.28  on 721  degrees of freedom\nAIC: 591.28\n\nNumber of Fisher Scoring iterations: 5\n\nlogreg_preds &lt;- predict(logreg_fit3, heart_test_logreg)\n\nconfusionMatrix(logreg_preds, heart_test_logreg$HeartDisease)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction yes no\n       yes  88 22\n       no   13 60\n                                         \n               Accuracy : 0.8087         \n                 95% CI : (0.7442, 0.863)\n    No Information Rate : 0.5519         \n    P-Value [Acc &gt; NIR] : 2.522e-13      \n                                         \n                  Kappa : 0.6093         \n                                         \n Mcnemar's Test P-Value : 0.1763         \n                                         \n            Sensitivity : 0.8713         \n            Specificity : 0.7317         \n         Pos Pred Value : 0.8000         \n         Neg Pred Value : 0.8219         \n             Prevalence : 0.5519         \n         Detection Rate : 0.4809         \n   Detection Prevalence : 0.6011         \n      Balanced Accuracy : 0.8015         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\nOur best logistic regression model gets about 80% accuracy on the test set compared to a NIR of 55%. Pretty good!\n\n\nTree fits\nNow we’ll train three different sets of tree models:\n\nClassification trees using rpart\nRandom forests using rf\nBoosted trees using gbm\n\nI personally prefer using the ranger package for random forests due to speed (C++ under the hood) and lightgbm for boosted trees due to speed/higher memory efficiency!\nSince trees do implicit variable selection, I’m just going to use the entire predictor set for the same data used to train the logistic regression models. We’ll create three different data.frames to specify tuning grids for each algorithm.\nAs before, we’ll compare model performances visually.\n\nset.seed(123)\n# tuning grids\nrpart_grid &lt;- data.frame(cp = seq(0, .1, by = 0.001))\nrf_grid &lt;- data.frame(mtry = 1:ncol(heart_train_logreg))\ngbm_grid &lt;- expand.grid(\n  n.trees = c(25, 50, 100, 200),\n  interaction.depth = 1:3,\n  shrinkage = 0.1,\n  n.minobsinnode = 10\n)\n\n# tree fits\nrpart_fit &lt;- train(HeartDisease ~ ., \n                   data = heart_train_logreg,\n                   method = 'rpart',\n                   trControl = train_ctrl,\n                   tuneGrid = rpart_grid)\n\nrf_fit &lt;- train(HeartDisease ~ ., \n                   data = heart_train_logreg,\n                   method = 'rf',\n                   trControl = train_ctrl,\n                   tuneGrid = rf_grid)\n\n# verbose = FALSE to prevent console output from being too cluttered\ngbm_fit &lt;- train(HeartDisease ~ ., \n                   data = heart_train_logreg,\n                   method = 'gbm',\n                   trControl = train_ctrl,\n                   tuneGrid = gbm_grid,\n                   verbose = FALSE)\n\ntree_results &lt;- resamples(list(rpart = rpart_fit, rf = rf_fit, gbm = gbm_fit))\nbwplot(tree_results)\n\n\n\n\n\n\n\n\nAll the models do pretty well and perform close to each other so we’ll evaluate all three on the test set.\nFirst, let’s grab the test set predictions for each model. Then we’ll look at each confusion matrix separately.\n\nrpart_preds &lt;- predict(rpart_fit, heart_test_logreg)\nrf_preds &lt;- predict(rf_fit, heart_test_logreg)\ngbm_preds &lt;- predict(gbm_fit, heart_test_logreg)\n\n\nClassification tree performance\n\n# rpart confusion matrix\nconfusionMatrix(rpart_preds, heart_test_logreg$HeartDisease)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction yes no\n       yes  91 31\n       no   10 51\n                                          \n               Accuracy : 0.776           \n                 95% CI : (0.7086, 0.8342)\n    No Information Rate : 0.5519          \n    P-Value [Acc &gt; NIR] : 2.317e-10       \n                                          \n                  Kappa : 0.5358          \n                                          \n Mcnemar's Test P-Value : 0.001787        \n                                          \n            Sensitivity : 0.9010          \n            Specificity : 0.6220          \n         Pos Pred Value : 0.7459          \n         Neg Pred Value : 0.8361          \n             Prevalence : 0.5519          \n         Detection Rate : 0.4973          \n   Detection Prevalence : 0.6667          \n      Balanced Accuracy : 0.7615          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\nRandom forest performance\n\nconfusionMatrix(rf_preds, heart_test_logreg$HeartDisease)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction yes no\n       yes  93 19\n       no    8 63\n                                          \n               Accuracy : 0.8525          \n                 95% CI : (0.7926, 0.9005)\n    No Information Rate : 0.5519          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.6979          \n                                          \n Mcnemar's Test P-Value : 0.05429         \n                                          \n            Sensitivity : 0.9208          \n            Specificity : 0.7683          \n         Pos Pred Value : 0.8304          \n         Neg Pred Value : 0.8873          \n             Prevalence : 0.5519          \n         Detection Rate : 0.5082          \n   Detection Prevalence : 0.6120          \n      Balanced Accuracy : 0.8445          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\nGradient boosting performance\n\nconfusionMatrix(gbm_preds, heart_test_logreg$HeartDisease)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction yes no\n       yes  92 15\n       no    9 67\n                                          \n               Accuracy : 0.8689          \n                 95% CI : (0.8112, 0.9141)\n    No Information Rate : 0.5519          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.733           \n                                          \n Mcnemar's Test P-Value : 0.3074          \n                                          \n            Sensitivity : 0.9109          \n            Specificity : 0.8171          \n         Pos Pred Value : 0.8598          \n         Neg Pred Value : 0.8816          \n             Prevalence : 0.5519          \n         Detection Rate : 0.5027          \n   Detection Prevalence : 0.5847          \n      Balanced Accuracy : 0.8640          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\nThe test set results for our tree models show that random forest has the best accuracy given this data, with an optimal mtry hyperparameter value of 1.\n\n\n\nWrap up\nBased on the test set evaluation results, the random forest model predicts at 85% accuracy, beating the other models."
  }
]